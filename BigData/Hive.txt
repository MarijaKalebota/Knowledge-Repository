## Hive

### Installation

https://www.tutorialspoint.com/hive/hive_installation.htm

You need to have both Java and Hadoop installed.

Download Hive. Unpack it with tar -xzvf apache-hive-x.y.z-bin.tar.gz.

Add to .bashrc.

 export HIVE_HOME=/path/to/your/hive !!
 export PATH=$PATH:$HIVE_HOME/bin
 export CLASSPATH=$CLASSPATH:/path/to/your/hadoop/lib/*:. !!
 export CLASSPATH=$CLASSPATH:/path/to/your/hive/lib/*:. !!

Use command to refresh the script: source ~/.bashrc

Check paths and create config file from a template.
cd $HIVE_HOME/conf
cp hive-env.sh.template hive-env.sh

hive.env.sh

Add export HADOOP_HOME=/path/to/your/hadoop !!

### Configure Metastore - Apache Derby

https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration

TODO


### Test installation

Don't forget to run start-dfs.sh, also known as Hadoop, first.

Test using bin/hive in the /path/to/your/hive folder.

### Hive Streaming

https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest
https://community.hortonworks.com/articles/49949/test-7.html

hive-site.xml

Hive.txn.manager                = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
Hive.compactor.initiator.on     = true
Hive.compactor.worker.threads   = 1 (greater then 0)

Hive.support.concurrency        = true
Hive.enforce.bucketing          = true
Hive.exec.dynamic.partition.mode= nonstrict
Hive.txn.timeout                = 300

Table has to be "store as orc" and "transactional"="true" and must be bucketed but not sorted and users need to have special permissions.
Example:
 CREATE TABLE alarms (stamp TIMESTAMP, state STRING, status_code STRING, down TINYINT, type STRING, info STRING)
 CLUSTERED BY(stamp) INTO 10 BUCKETS
 STORED AS ORC
 tblproperties("transactional"="true");

