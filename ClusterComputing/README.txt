Introduction to Apache Spark
============================

Apache Spark allows a computation to be performed across many different computers at the same time. It abstracts data by creating a Resilient Distributed Dataset (RDD) and allows the user to perform actions and transformations on it. It also abstract the computer cluster through the Spark Context.